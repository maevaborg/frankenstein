http://192.168.1.93:8888 = ethernet
http://192.168.5.134:8889 = wifi random
http://192.168.150.201:8888 = local 

-----------------------------------
Présentation du projet / rendu 
-----------------------------------

texte d'intention (15 à 30l)
flow charts
mindmapping 
references

http://gutenberg.org

-------------------------------------
6/02 analyse de données avec panda / dataset
-------------------------------------

à rattrapper 

--------------------------
13/02 utilisation des librairies PoS / google dorking.logs 
-------------------------- 

GOOGLE DORK(ING)
recherches très précises, methodes qui permettent de changer le comportement du moteur de recherche (extension de fichiers,url,date)
exemple 
filetype:csv
inurl:robot.txt
cibler un site et chercher une chaine de caractère dans le site

2 librairies : NLTK (natural langage toolkit) + contextual-free grammars
C-F G = simuler le langage naturel -> à nous de determiner le modèle de phrases (equivalent sur javascript : RiTa.js)

-------------------------------------
stopwords librairies 

    part of speech tagging
    
    regex = regex101 https://regex101.com/
    stackoverflow
    doublon 
    set 
    transformer une liste en set
cf 
dossier agent pour le code 
---------------------------------------
irc = internet relay chat  -> installer un serveur via un terminal on peut discuter avec des gens 
chercher "sujet" filetype:log
text format (fileinfo) https://fileinfo.com/filetypes/text

=====

logs interesssants

https://www.cs.hmc.edu/~jhsu/daoc/chat.log
https://svn.apache.org/repos/asf/pig/trunk/tutorial/data/excite-small.log
http://misclab.umeoce.maine.edu/research/bgcfloats/floatdata/7708/001/log/7708.1112220528.011.log
http://transcripts.jboss.org/channel/irc.freenode.org/%23windup/2019/%23windup.2019-01-21.log
https://github.com/Bunlong/chat/blob/master/log/error.log
https://blog.ebrahim.org/media/msie_teamchat_20040608.log

--------------------------
20/02 : webscrapping sites et apprentissage des fonctions 
--------------------------

webscrapping sites 
apprentissage des fonctions 
exemple : site aaron schwartz
le code marche en fonction d'une url précise exemple ici "http://qblog.aaronsw.com/page/2"
dessin du flowchart du code python 3 (cf carnet) 
passage de jupyter -> editeur de txt

nouvelle fonction qui permet de récupérer ce qu'on a récolté

fonction principale = main
permalink = la date (sur le site)
realpost = texte qui correspond à la datz

apprentissage des classes?

______

terminal
______ 

clear ou ctrl+l = pour nettoyer le terminal 
ctrl shift v = coller 
mkdir = créer un dossier
cd 
ls 
pip install nom
python scrap.py 'http://qblog.aaronsw.com/' 5 'scrap'



appel d'une librairie pour un script plus intelligent = sys 
argv = element renvoie une liste pour recuperer ces elements
str = chaine de caractere
int = nombre entier 


---------
6/03
---------

zzzzzzz


-------
13/03
--------
utilisation des chaines de markov 
generation de nouveaux mots, basé sur le texte qu'on lui donne à manger
exemple de doudou le hamster wtf 

"the death of the authors" CONSTANT 
http://www.tbook.constantvzw.org/wp-content/death_authorbarthes.pdf

http://constantvzw.org/site/The-Death-of-the-Authors-1943,2324.html?lang=en

https://publicdomainday.constantvzw.org/

NLTK / PoS / 

in range" = crée une liste de chiffres, definit la longue
es à': 
plus on a des fragment petit plus ce sera précis 

-------
20/03 
-------

Matin -> exercices sur jupyter : 

1: cf fichier words 
A partir des codes dans nos fichiers, réaliser un code exécutatble sur jupiter et après sur un truc type atom; vsc 
- ouvrir et parser un fichier texte
- isoler les éléments du texte (concept tokenize, librairie ntlk), découper des phrases en mot (attention besoin d'autres librairies)
-> identifier dans les mots les nims et les stocker dans une liste 
- enregistrer le résultat dans un fichier texte

objectif : utiliser des fonctions (même si pas obligé)
et savoir réécrire le script sans jupyter 


aller voir dans grammaire contextuelle et tags 

------------------------------------
27/03
-----------------------------------

exercice :
-on ecrit un programme pour collecter le texte d'un site web à partir d'une balise html
-le programme prend 2 arguments : url du site et la balise
- optionnel : si la balise n'existe pas, le programme renvoie un message d'erreur
- optionnel : tester s'il y a du texte mm si il y a la balise 

- le code est structur par des fonctions
- finalise le programme sous forme d'un script 

méta content

récupérer <img alt=">
utilisation d'une librairie
identifier un site 
structure arbre html 
requête url > 
récupère la page
parser l'html
récupération sous forme d'une liste -> conversion 


